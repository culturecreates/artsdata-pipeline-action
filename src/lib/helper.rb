require_relative '../page_fetcher_service/page_fetcher'
require_relative '../page_fetcher_service/static_page_fetcher'
require_relative '../page_fetcher_service/headless_page_fetcher'
require_relative '../graph_fetcher_service/graph_fetcher'
require_relative '../graph_fetcher_service/linkeddata_graph_fetcher'
require_relative '../browser_service/browser'
require_relative '../browser_service/chrome_browser'
require_relative '../sparql_service/sparql'
require_relative '../file_saver_service/file_saver'
require_relative '../file_saver_service/github_saver'
require_relative '../notification_service/notification'
require_relative '../notification_service/webhook_notification'
require_relative '../databus_service/databus'
require_relative '../spider_crawler_service/spider_crawler'
require_relative '../url_fetcher_service/url_fetcher'

module Helper
  def self.check_mode_requirements(mode, config)
    required_map = {
      "fetch"      => %w[page_url],
      "push"       => %w[artifact publisher download_url],
      "fetch-push" => %w[page_url artifact publisher]
    }

    keys_to_check = required_map.select { |k, _| mode == k }.values.flatten.uniq
    missing = keys_to_check.select { |key| config[key].nil? }

    unless missing.empty?
      puts "Missing required parameter(s) in config file: #{missing.join(', ')}. Exiting..."
      exit(1)
    end
  end

  def self.get_headers(custom_user_agent)
    linkeddata_version = Gem::Specification.find_by_name('linkeddata').version.to_s
    { "User-Agent" => custom_user_agent == nil ? "artsdata-crawler/#{linkeddata_version}" : custom_user_agent }
  end

  def self.format_urls(page_url)
    page_url = page_url.split(',')
    base_url = page_url.first.split('/')[0..2].join('/')
    [page_url, base_url]
  end

  def self.get_page_fetcher(is_headless:, headers:)
    if is_headless
      PageFetcherService::HeadlessPageFetcher.new(headers: headers, browser: BrowserService::ChromeBrowser.new)
    else
      PageFetcherService::StaticPageFetcher.new(headers: headers)
    end
  end

  def self.get_url_fetcher(page_url:, base_url:, entity_identifier:, is_paginated:, offset:, page_fetcher:)
    UrlFetcherService::UrlFetcher.new(
      page_url: page_url,
      base_url: base_url,
      entity_identifier: entity_identifier,
      is_paginated: is_paginated,
      offset: offset,
      page_fetcher: page_fetcher
    )
  end

  def self.get_graph_fetcher(headers:, page_fetcher:, sparql_path:, html_extract_config:)
    GraphFetcherService::LinkedDataGraphFetcher.new(
      headers: headers,
      page_fetcher: page_fetcher,
      sparql: SparqlService::Sparql.new(sparql_path),
      html_extract_config: html_extract_config
    )
  end

  def self.get_github_saver(repository:, file_name:, token:)
    FileSaverService::GitHubSaverService.new(
      repository: repository,
      path: file_name,
      message: 'Add data generated by the script',
      access_token: token,
      author_name: 'GitHub Actions',
      author_email: 'actions@github.com'
    )
  end

  def self.get_databus_service(artifact:, publisher:, repository:, databus_url:)
    DatabusService::Databus.new(
      artifact: artifact,
      publisher: publisher,
      repository: repository,
      databus_url: databus_url
    )
  end

  def self.get_spider_crawler(url:, page_fetcher:, sparql_path:)
    SpiderCrawlerService::SpiderCrawler.new(
      url: url,
      page_fetcher: page_fetcher,
      sparql: SparqlService::Sparql.new(sparql_path)
    )
  end

  def self.fetch_types(graph:)
    graph.query([nil, RDF.type, nil]).map(&:object).uniq
  end
end
